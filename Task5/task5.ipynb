{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kb_PVxXaW2Qy"
   },
   "source": [
    "# <a href=\"https://miptstats.github.io/courses/ad_fivt.html\">Введение в анализ данных</a>\n",
    "## Домашнее задание 5. Компьютерное зрение & генеративные модели\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "duMi1QifW2Qz"
   },
   "source": [
    "**Правила, <font color=\"red\">прочитайте внимательно</font>:**\n",
    "\n",
    "* Выполненную работу нужно отправить телеграм-боту `@miptstats_ds24_bot`. Для начала работы с ботом каждый раз отправляйте `/start`. **Работы, присланные иным способом, не принимаются.**\n",
    "* Дедлайн см. в боте. После дедлайна работы не принимаются кроме случаев наличия уважительной причины.\n",
    "* Прислать нужно **ноутбук в формате `ipynb`**.\n",
    "* Следите за размером файлов. **Бот не может принимать файлы весом более 20 Мб.** Если файл получается больше, заранее разделите его на несколько.\n",
    "* Выполнять задание необходимо полностью самостоятельно. **При обнаружении списывания все участники списывания будут сдавать устный зачет.**\n",
    "* Решения, размещенные на каких-либо интернет-ресурсах, не принимаются. Кроме того, публикация решения в открытом доступе может быть приравнена к предоставлении возможности списать.\n",
    "* Для выполнения задания используйте этот ноутбук в качестве основы, ничего не удаляя из него. Можно добавлять необходимое количество ячеек.\n",
    "* Комментарии к решению пишите в markdown-ячейках.\n",
    "* Выполнение задания (ход решения, выводы и пр.) должно быть осуществлено на русском языке.\n",
    "* Если код будет не понятен проверяющему, оценка может быть снижена.\n",
    "* Никакой код из данного задания при проверке запускаться не будет. *Если код студента не выполнен, недописан и т.д., то он не оценивается.*\n",
    "\n",
    "\n",
    "**Баллы за задание:**\n",
    "\n",
    "* Задача 1 &mdash; 150 баллов\n",
    "* Задача 2 &mdash; 40 баллов\n",
    "\n",
    "Баллы учитываются в <b><font color=\"green\">факультативной части</font></b> курса и не влияют на оценку по основной части."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "pWZ4wmCvW2Q0",
    "ExecuteTime": {
     "end_time": "2024-03-15T21:54:39.056840Z",
     "start_time": "2024-03-15T21:54:39.027406Z"
    }
   },
   "outputs": [],
   "source": [
    "# Bot check\n",
    "\n",
    "# HW_ID: fpmi_ad5\n",
    "# Бот проверит этот ID и предупредит, если случайно сдать что-то не то.\n",
    "\n",
    "# Status: not final\n",
    "# Перед отправкой в финальном решении удали \"not\" в строчке выше.\n",
    "# Так бот проверит, что ты отправляешь финальную версию, а не промежуточную.\n",
    "# Никакие значения в этой ячейке не влияют на факт сдачи работы."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "#!pip install torchinfo"
   ],
   "metadata": {
    "id": "Oh_JpvACb7Z6",
    "ExecuteTime": {
     "end_time": "2024-03-15T21:54:39.330199Z",
     "start_time": "2024-03-15T21:54:39.320973Z"
    }
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import time\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchinfo import summary\n",
    "\n",
    "from IPython.display import clear_output\n",
    "sns.set(font_scale=1, style='darkgrid', palette='Set2')\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "device = f\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ],
   "metadata": {
    "id": "o2-SbeG5x3oj",
    "ExecuteTime": {
     "end_time": "2024-03-15T21:54:55.443531Z",
     "start_time": "2024-03-15T21:54:39.967756Z"
    }
   },
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2M__0kK2W2Q1"
   },
   "source": [
    "Перед выполнением задания обязательно посмотрите <a href=\"https://miptstats.github.io/courses/ad_fivt/lecture5_1.pdf\" target=\"_blank\">презентацию</a> и <a href=\"https://miptstats.github.io/courses/ad_fivt/CV_classification.html\" target=\"_blank\">ноутбук</a> про сверточные сети и классификацию, а так же <a href=\"https://miptstats.github.io/courses/ad_fivt/lecture5_2.pdf\" target=\"_blank\">презентацию</a> и <a href=\"https://miptstats.github.io/courses/ad_fivt/CV_complex_examples.html\" target=\"_blank\">ноутбук</a> про перенос стиля и генеративные сети."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x-9Z1rmVW2Q1"
   },
   "source": [
    "---\n",
    "### Задача 1. Классификация MNIST\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Цель: сравнить сверточные нейросети с разными параметрами на датасете рукописных цифр MNIST. В нем содержатся черно-белые изображения цифр, всего 10 классов для каждой цифры. Пользоваться кодом семинара можно без ограничений. Классификация MNIST намного легче, чем CIFAR, поэтому ваша задача хотя бы в одной из моделей получить 98% точности **на валидации**.\n",
    "\n",
    "> Использования слоев с семинара (свертка, pooling) более чем достаточно для достижения 98% точности на тесте. Также не делайте сеть глубокой.\n",
    "\n",
    "> Тестируйте работоспособность кода на CPU с небольшим кол-вом итераций. Если все работает, и хочется ускорить процесс, переходите на GPU.\n",
    "\n",
    "Следуйте указаниям ниже."
   ],
   "metadata": {
    "id": "FiPesei5d_6Y"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Загрузим датаcет из `torchvision.datasets`."
   ],
   "metadata": {
    "id": "aZiM2W4leua-"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Данные для обучения\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                           download=True,\n",
    "                                           transform=transforms.ToTensor())\n",
    "# Данные для тестирования\n",
    "val_dataset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                         download=True,\n",
    "                                         transform=transforms.ToTensor())\n",
    "# Классы объектов в датасете\n",
    "classes = [str(i) for i in range(10)]"
   ],
   "metadata": {
    "id": "rIaFpD-8wmnc",
    "ExecuteTime": {
     "end_time": "2024-03-15T21:56:38.279639Z",
     "start_time": "2024-03-15T21:56:34.142247Z"
    }
   },
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:02<00:00, 4840546.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 10277058.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:00<00:00, 3169680.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 10138652.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Визуализируйте несколько картинок с соответствующими метками из датасета."
   ],
   "metadata": {
    "id": "S1y77vr0eyzK"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Создадим функцию для визуализации картинки."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def DrawPic(df, idx, df_name, value):\n",
    "    plt.imshow(df[idx][0].permute(1, 2, 0))\n",
    "    plt.title(f\"{df_name}[{idx}]: {value[df[idx][1]]}\")\n",
    "    plt.axis(\"off\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T22:06:27.495341Z",
     "start_time": "2024-03-15T22:06:27.483649Z"
    }
   },
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "source": [
    "# берем 2 рандомных индекса\n",
    "train_idx1_visual, train_idx2_visual, val_idx_visual = np.random.randint(0, 10000, 3)\n",
    "print(f\"Размер картинки:{train_dataset[0][0].shape}\")\n",
    "\n",
    "plt.figure(figsize=(4, 2))\n",
    "plt.subplot(131)\n",
    "DrawPic(train_dataset, train_idx1_visual, \"train\", classes)\n",
    "\n",
    "plt.subplot(132)\n",
    "DrawPic(train_dataset, train_idx2_visual, \"train\", classes)\n",
    "\n",
    "plt.subplot(133)\n",
    "DrawPic(val_dataset, val_idx_visual, \"value\", classes)"
   ],
   "metadata": {
    "id": "LnpGySak1woQ",
    "ExecuteTime": {
     "end_time": "2024-03-16T05:54:25.872396Z",
     "start_time": "2024-03-16T05:54:25.273062Z"
    }
   },
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер картинки:torch.Size([1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 400x200 with 3 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVMAAACDCAYAAAAwAvjvAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAes0lEQVR4nO3de1xNWf8H8M/pVFRUMg+500SjlAplxKSMyZB4DJPrDKKJXPKQ8uSau5joRqHkfqufxz0yEipmIswol9wdk0mlUnQ7vz+8WufsOqfO0e6C7/v16vX67r3X3nudvTrrrLX2TSAWi8UghBBSIyr1nQFCCPkUUGVKCCE8oMqUEEJ4QJUpIYTwgCpTQgjhAVWmhBDCA6pMCSGEB1SZEkIID5SuTOka/48PlRkhtU+pyvTcuXPw8vLiZcfR0dEwMjLCs2fPlF7HyMgI33zzDZ49e8amZf0tWLCArZubm4ulS5fCxsYGFhYWcHZ2RmJiotx97dy5E/b29pXmp6eny9zXoEGDAAD+/v5s3oQJE5Q4Iu/FxMRg5MiRsLS0hK2tLby9vZGZman0dso1tDIrFxsbixEjRsDCwgIDBw5EUFAQioqK2HJ7e3u55SpdLvv27ZOZZvHixTLz8+eff8LExITzGWpaZtHR0XB0dISpqSns7e0REBCA4uJipbdTU1euXIGRkRGuXLnC+7aly+PQoUMAFDv2JSUlCAsLw3fffQdzc3MMGzYMJ0+elLuf/Px82NvbIzo6utKy33//HWPHjoWFhQX69u2LFStWID8/n+1HOg/KHoOMjAzMnTsXVlZWsLS0xOTJk3Hz5k2ltqGqTOIdO3YotfGq9O/fHwcOHECLFi2UXjcoKAht2rRBixYtcODAgUrL9+zZg1OnTuGHH34AAJSWlmLq1KkQiUTw9PRE8+bNsXPnTri6uuLQoUP46quvOOsfPXoUa9euRcuWLSttOy0tDcD7yrZRo0ZsfuPGjQEAY8aMgZ2dHZYtW6b05zp16hQ8PDzg7OwMDw8PZGZmIiAgAD///DOio6M5+1NUQyszALh8+TJmzJiBwYMHY+7cubh79y5+/fVXZGVlsS9ixcoVAFJSUrB69WqMHj2azUtNTYWhoSFWrlzJSdu8efNKeUhLS8Mvv/yCkpISzvyalFlkZCRWrVoFBwcHeHp6Ijs7G4GBgbhz5w6Cg4OV3l5DZmtri+nTp6N9+/YAFDv2gYGBCAsLg7u7OywtLRETE4M5c+ZARUWFNUDK5eTkYNq0aXj+/Hmlfd++fRsuLi7o06cPAgMD8fLlS2zYsAEPHjxAeHg4VFVVceDAAfz111/w9fVV6nPl5eVhzJgxKCwsxOzZs9GxY0ecPXsW48ePx65du9C9e3eFtqNUZconPT096OnpfdC6Xbt2Rdu2bQEA5ubmnGW3bt3CqVOnMGfOHPTs2RMAcOzYMdy6dQvR0dGs4rSysoKTkxMuX77M5r169QobN27EwYMHoaurK3PfqampaNOmDaytrWUu19fXh76+Ppo0aaL05woJCYGtrS3nn8HAwACjRo3C+fPnK/3z1TW+yiw6OhqtW7eGn58fhEIhbGxs8OrVK+zYsQMLFiyAmpoajI2NOevn5+fjP//5D/r37w9XV1c2Py0tDWZmZpX+D6QVFRVh9+7d2LRpE/vRk/ahZVZaWorg4GDY2NggICCAze/WrRuGDBmCy5cvw8bGRqltNmR6enqc46zIsY+KioKjoyNmzJgBAOjTpw9SU1OxZ88ezv9zbGwsVq5ciYKCApnbiYiIgJ6eHgICAqCurs7mL1iwAA8ePICBgQHMzc3x7t07pT9XVFQUnj9/jn379sHS0hIAYGNjg+zsbKxevRr79+9XaDsKd/MnTJiAq1ev4urVq6wZXd6t2L9/P+zs7NCnTx9cunQJAHDo0CGMGDEC5ubmMDMzq9S8r9hl9Pb2xsSJExEVFQUHBwd069YNTk5OuHDhgsIHRSwWY9myZTAwMMDEiRPZ/JiYGPTq1YvTAm3UqBFiYmLg4uLC5m3ZsgWXL19GYGAg7OzsZO4jNTUVXbt2VThP5by9vWFkZCR3eVlZGWxsbPDjjz9y5nfq1AkA8OTJE6X32VDLrKioCBoaGhAKhWxes2bNUFxcjDdv3shcJzg4mNNyBd4fs7t371bqWVQUHx+PoKAguLm5Yd68eVUfNCnVlVlmZiZev35d6X/F0NAQzZo1w/nz5xXaz6JFi9C7d+9KLWY/Pz9YWVmxFnpsbCzr5nbr1g2DBg3C7t275W43MDBQZv6NjIwQGBjIpt+9e4d169bB1tYW3bp1w9ChQ6vsigOKH/vi4uJKP1LNmjVDTk4Om87NzcXMmTNhZWWFbdu2ydzO3LlzsWXLFk5FqqamBgCVejDSyocCpT9vRenp6dDR0WEVaTkrKytcv34dr1+/lruuNIUr0yVLlsDY2BjGxsY4cOAATExM2DJ/f394eXnBy8sL5ubm2LNnDxYvXowBAwYgNDQUfn5+UFNTg6enJ0Qikdx9/Pnnn9i+fTtmzZqF4OBgqKqqYtasWQp/mOPHj+PWrVvw8fHhfFHT0tLQuXNn7NixA/b29jA2Nsa///1vXL16lbP+6NGjERMTg++++07uPtLS0pCXlwdnZ2eYmprCxsYG69evr3aMbPr06TKHJMqpqKjA29sb3377LWf+mTNnAABdunSpcvuyNNQyGzduHB4/foxt27YhNzcXKSkpiIyMhK2trcwewbNnz7Br1y64uLiwoQIAePjwIQoLC3Hjxg04ODjAxMQEDg4OOHLkCGd9U1NT/Pbbb5g2bRrn/6I61ZWZtrY2VFVVK3VLX79+jdzcXIXHlocNG4bs7GzOGL5YLMbJkycxaNAgqKurIy4uDu7u7jAxMUFISAgCAwPRpk0bLF++HNeuXVP4M1UkFovh7u6O/fv3Y9KkSdi8eTMsLCwwZ86cSsdRmqLHfuLEiThy5Aji4+ORn5+Po0eP4uLFixg2bBhL07hxY5w4cQJr165Fs2bNZO5PX1+fVdxv3rxBQkIC/P390bNnzyor9PKhwFGjRslNo6enh/z8/Er/s+UNGEXLUeFuvqGhIfuFqdisHz16NKfJ/vTpU0yePBnu7u5sXtu2bTFixAhcu3YNrVu3lrmPvLw8REdHszEZTU1NjB8/HklJSXBwcKg2j+Hh4bC0tKzUBc/KysLp06eho6OD+fPnQ0NDA2FhYXBxccHBgwdZS/PLL7+scvuZmZnIzMyEQCDAvHnz0Lp1ayQmJmLr1q148eIFNmzYIHfd9u3bs8+lqEePHmHdunUwMTHhnLxRVEMtM2tra7i4uMDPzw9+fn4AAGNjY7nHb+fOnVBXV8dPP/3EmV8+fi0SieDt7Q1VVVUcOXIEXl5eKCoqYq18WWPfiqiuzDQ0NPD9999j9+7dMDQ0xMCBA/Hq1SusXLkSqqqqKCwsVGg/PXr0QNu2bXHy5En069cPAJCcnAyRSMQqnfv372P48OHw8fFh61lYWMDa2hq///57pVaVohISEnDx4kX4+/tj8ODBAIB+/fqhsLAQ69evh6OjI1RVK1cTih77CRMm4I8//sDUqVPZuj/88AOmTJnCptXV1WFgYKBQfsViMaytrVFcXAxdXd1qT66qq6tXOQwBAEOHDsX27dsxe/Zs+Pj4oGXLloiLi2MnwRQtR17GTCt2Jby9vQG8/6I9evQIjx49Yr+6VbXg9PT0OP+8+vr6ABT7MMnJybh9+7bMQf/i4mLk5eXh8OHDbJs9evTAwIEDsXXrVvz666/Vbh8AmjRpgoiICHTq1AmtWrUC8L4roK6ujo0bN2L69OnVVsiKSk9Px6RJk6Curo5NmzZBRYXfS4Lrs8yWLFmC6OhoTJs2DV9//TWePXuGwMBATJkyBTt27ICGhgZL+/btWxw+fBgjR46Ejo4OZzvW1tYICwuDtbU1Gwvt168fsrKyEBAQgFGjRkEgEChyOD7YsmXLoK6ujoULF8LHxwcaGhqYMmUK3r59y/kcVREIBHBycsKuXbvY9o4fP4527dqhR48eAMAqn4KCAjx58gQPHz7ErVu3AFRdPtVJTEyEQCCAra0tZ5jB3t4eR48exb1792QOayly7IuLizF27FhkZmay4bfk5GRs2bIFmpqaWLhwodL5LSkpwZYtW1BaWoqdO3di3Lhx2Lp1K3r37v3Bx8DQ0BBbtmzB4sWL4ejoCAAwMTGBh4cHfH19FS5HXirTimdOnzx5gsWLFyMpKQmqqqowMDBgX96qrnmsmOnyL0JZWVm1eYiJiYGOjg5sbW0rLdPS0sKXX37JvujA+4rRwsICqamp1W67XOPGjdGnT59K8/v374+NGzciLS2Nl8o0KSkJM2fOhJaWFsLDw9GuXbsab7Oi+iqzjIwMHDx4EL/88gs8PDwAvP9impqaYujQoYiKisL48eNZ+kuXLuHNmzcYOnRopW198cUXMsvb1tYWCQkJyMzMxL/+9S+5eeeDlpYWVq1aBR8fH4hEIrRp0waampqIioqSe5JSluHDhyMkJATx8fHo378/Tp8+jbFjx7LlWVlZWLJkCWJjYyEQCNChQwdW0dbkOuKcnByIxWK5LduXL1/KrEwVOfZJSUm4c+cOIiIi2PfGysoK2tra8PX1xahRo6ock5ZFTU0Nffv2BQB8/fXXcHR0RGhoaI0qUwDo27cvzp07x7r07dq1Q1RUFABU+hGXh/ez+WVlZXB1dYWamhoOHjwIY2NjqKqq4v79+zh69Cjfu2Pi4uIwYMAANigtrUOHDjIHqUtKSmSe3ZXnwYMHuHLlCoYOHcoZVH/79i0AyB3vUcaxY8ewYMECdOzYEdu2beP8ANSWuiwzkUgk88vbpUsX6Orq4t69e5z5cXFxaNu2LUxNTStt6+rVqxCJRBg+fDhn/rt37yAUChX+EtTE+fPnoa2tjR49eqBz584A3l8V8uLFi0pXJFSlQ4cOMDc3x6lTp6Cmpobs7Gw4OTmx5fPmzUN6ejoiIiJgaWkJdXV1FBYWsms+ZSn/YSstLWVjxRVP8DVt2hSamprYuXOn3HzJosixLx9rr1jWvXr1AiC5ZlsR586dg7a2NlsXeN+FNzIyqvQ/oyyRSISEhAQ4OTlxGi5//fUXdHV1OeP0VVGq76hIVzM7OxsPHz7EyJEjYWZmxsZb4uPjASjWylRWTk4OHj9+LPfX1dbWFqmpqUhPT+fk89q1a+zXXREZGRlYunQpTp8+zZl/8uRJaGlpcU7wfIgLFy7Ay8sLFhYW2LdvHy8VaUMrsw4dOkAoFCI5OZkz/8GDB8jJyWGXT5W7ceOG3HJNTEyEt7c3Hj9+zOaVlZUhJiYG3bt355z5rS379+/HunXrOPMiIyMhFArlXhEij5OTE+Lj43H8+HGYm5ujY8eObFlycjIcHBzQu3dv9rmqK5/yH/wXL16weRVPVllZWaGgoABisRimpqbs7969ewgODq50hUE5RY59+TjoH3/8wVm3PA8Vy7oq4eHhWLJkCSc/eXl5uH79erVXFFTn1atX8PHx4Vzo/88//+DEiRMYMGCAwkNFSrVMtbW1cf36dSQmJsr91W3evDnatGmDPXv2QF9fH9ra2rh06RIiIyMBKD6Yq4y7d+8CeD/2IctPP/2E6OhouLq6Ys6cOdDU1ERISAgEAgFnILw6VlZWsLKywpo1a1BYWAgDAwPExcVh165dmD9/fpUtoSdPniArK0vuYPi7d+/g4+MDLS0tuLm5cSp+QHItpLIaWpnp6enh559/xvbt2wG8v+5QJBIhKCgIrVu35lwaVlpaigcPHrBxrIrGjBmDAwcOwM3NDTNnzoSGhgb27NmDu3fvym1pKaO6MgPen2BxcXHBypUrYW9vj6SkJISGhsLV1VXp4ZkhQ4Zg9erVOHHiBOdEEwCYmZnh2LFjMDExgb6+Pq5fv47Q0FAIBAK55WNra4vVq1dj0aJFmDp1Kv7++28EBQVBS0uLk6ZXr16YPn06G/O/efMmAgMD0bdvX7nXFSty7O3t7dG9e3d4enpi5syZMDAwwM2bN7F582bY2dnBzMxM4WPj7u4OFxcXzJo1C2PGjEF+fj62bt2KwsJCzJw5U+56RUVFuH37dpXfn27dusHS0hJLly7F/PnzIRQKsXHjRgiFQnZ9rCKUapmOGzcOampqmDp1KvtVlCUkJAQtW7aEt7c3PDw8kJKSgs2bN8PAwKDSrxQfym+31NbWlrlcR0cH+/btg7m5OXx9fTF37lzo6Ohg7969SlVQQqEQISEhGDFiBCIiIuDm5oaEhAT4+vpi8uTJVa4bEhICZ2dnucuvXbuGf/75B7m5uZg8eTKcnZ05f1V156rSEMts/vz58PT0xJkzZzBlyhQEBQXBxsYGUVFRnB+knJwclJSUyC3XFi1aYO/evejcuTNWrFgBDw8PvH37Fjt27Pjgs9vSqisz4P1Y24YNG5CQkAA3NzecOXMGCxcuxNy5c5Xen66uLmxtbaGiosLOrJdbs2YNunfvjuXLl8Pd3R2xsbFYtmwZ+vbtK7d8OnXqhLVr10IkEsHV1RWRkZFYvnw55w42FRUVhIWFYciQIQgNDYWLiwv279+PiRMnwt/fX25eFTn2QqEQ4eHhGDx4MEJCQjB16lQcOXIE06ZN49zkoIg+ffogPDwcr1+/xuzZs7Fo0SK0atUKBw8erPI8xcuXL6v9/ggEAgQGBsLc3ByLFy+Gj48PDAwMsHfvXrlXscgk/ohERUWJu3TpIn769Gl9Z6Va48ePF48fP76+s1HvqMw+DXZ2dmIvL6/6zka1kpKSxF26dBEnJSXV+b4/ykfwpaam4vbt2/WdDZn+/vtvpKSksAcwkPeozD5+WVlZSElJQVZWVn1nRaaUlBTcv3+/3vb/UVamM2bMgJubW31nQ6Z9+/bB2dm5wVYc9YXK7ON34cIFODs749y5c/WdlUpKSkrg7Oys9ENO+CQQi+lhl4QQUlMfZcuUEEIaGqpMCSGEB1SZEkIID6gyJYQQHnzQvflCNSUuZCU1Vlos/3miyqByq1t8lBuVWd2qSZlRy5QQQnhAlSkhhPCAKlNCCOEBVaaEEMIDqkwJIYQHVJkSQggPqDIlhBAeUGVKCCE84P2FevXhW33J6w/2mBVwljXduJrFpclnWbxxPvclXItenK+l3BFCPgfUMiWEEB5QZUoIITz4qLr50t35/1tpwWLV7yayWFDFq41V7MexeN5V7utx20m9f23iP9TlJ4Qoh1qmhBDCA6pMCSGEBw26mx/XvA9n2jppKYsFao1YXDBP8qI25/PqnHUuZ91h8Y6mvVnsdHMZJ90Pfp1YfOK/b1h8SHRVyVwTQj5H1DIlhBAeUGVKCCE8oMqUEEJ4IBCLxWJlV6rNVymEtrBn8YSLszjLVJo0Y3FQD8mY5/yMOBaXibmXPEkTqghZ/GKQAWeZ9tZtLE7vK9mvycMbCuS6dtFrSz5O9NqSjw+9toQQQuoZVaaEEMKDBndp1L8tn7BYulsPAAmmC1g8PzuJxVV17aWVlpWy+P7vepxllhUTk3rVXrsFi8/qS+LWC3tz0ql9+7NkQs7/QdHudZxpQ9/LLH75JqcGufw8qAgkba4h+pI7D/1133LStRgjGZJQn7KYxcXHtnDSqQ6ewuKModNYnP6kOYsnlXAfRPQk96Wy2a5z1DIlhBAeUGVKCCE8aHDd/K7xkua8dQ8PzrLT2ZIz64p27T9Eu3FSwwsram03pAqTm5iwuF2UK4sFuvqcdOLSkmq3peo0mTNt4f+cxTFvUj4wh5+29fqSq2qmjMxlcaP5axVaX7pcVL+fXGGh5Lvb8miwJJZKcvtOImeVjsP8WJxZ8FqhPNQ1apkSQggPqDIlhBAeUGVKCCE8aHBjpq8KJOMzJwuu10seVPr2l5qKq5c8fKqk70KzaC65Cy3GXshJp+E7m8UCTR0W506aykmX86Qxi1vP7c5i6ctvUFLEWedV6RsQoIm6BotPNe3OWdYj9hcWC7S/qNF+igIWcqbzEzJZrP2zFYulx1aFRl9z1rn9zb9Y3OI0jZkSQsgniypTQgjhQYPr5jcEJf/7X31n4ZO1SP8bFntdWSw3Xcn/NrM4bcUDFh9TacdJ52GXwWJO116KuIx7GV2JuFRmus9Np6aSi5F6Xl+p9PrZY9040za38lic+VYyXFdQ/I6TTvpOxC6pklez36h4CZUUrZX/ZXGT39xZnF9UqESOaxe1TAkhhAdUmRJCCA+omy/D89O1d3fV527Oj7LPpBfvXc+ZtvVLY3GYquSONM9VnTjpVAfIHyood/PbTZzplMwHclJ+XhJW9qk+EYDSG7EsDnSVPGAoVOrKGwB49DoDirBvacriQ/2LFVpH+ooOQ+1WLG5IZUktU0II4QFVpoQQwoPPqpuvqS65wNt0VRe56fzeadVFdj5ZOo25xy+1p+Q5l2quniwu+I/kbHDExTacdS7M/lKyzsQFUFbJ4QAWD3h9U+n1P1UWX0iOq9DuR7nppLv2/lJd+0Uvziu0H93GTVjs3cyKs2xGhOSKDqFxP4W2V3r+EIsbUtdeGrVMCSGEB1SZEkIID6gyJYQQHnxWY6Y+zSUPT1CrcLfMO39vFh/OTKmrLH2S2mg250zrhq1isaCp5KEZGiskDxp2e5jCWUdoYqv0fsX5WSxe5ZfN4oKit7KSf5Y6qUm9+0wo/+svfvqQxeuyrshMI/2gFADY3tSaxY4nnVms0kr++QlFrVjxd423UduoZUoIITygypQQQnjwWXXzp30r/3WxD/ZJHsbQkB6e8LFopy153mSclTpnmXTXnjNf6q6WD+nWV3TfQfLCrtWi+nkWbkNnLJBctlb2QvI6ZWEHM046gb7kUrU7vbiXrZXTXjqJMy3sIunmQ+r10PJewV2VksOBnOngTNlDDQ0JtUwJIYQHVJkSQggPPvlufvfmkgdjNJo+ncXiCl35NWK1OsvTp+grTcldTk38q3/4SEUlJ7ZypovOJrNYfZjkLhlVu3Fyt7G8hMqwOitEcSyed0jy0BnhPG43X9hzMIub7R0MRZReO83igrAjLN6fzH0Grcupn1is8oVkWdmLuyyevZ47JPcxDL1Ry5QQQnhAlSkhhPCAKlNCCOHBJzdmOr0N9yk0qydKfi+E7bux+OE3MznpDojoyUI1cfbvGywWjeCOmbacbixJt0QyFvZSVfJ658VvrnHXaazL4qR5FnL3mzNB8urnoy+fKJ5hAqPw+yy+824uZ1kjnw0y1ykKXsLimG3c6sOj6BaLRXmvWNxVj3sH2k87giX7mbeGxWKp8jv/pmE+Gaoq1DIlhBAeUGVKCCE8+CS6+atb2bF49gVud0VFoymLMxx/YbHVM+oS1hbD1L+4M2b+JTthFWKlLmlTaWssN93dW5I7r96V3JebjlSWkS95GIxuaDZ3YegA3vYTqabPmW7kuU5mOun3Sz183fAfbFIRtUwJIYQHVJkSQggPPtpuvk/r/iyeHS/p2gtUuQ/ZePG95D1DZnckXfu8dwW1lzmitI46LTnTnS+tl5mu4iuh7bOv1lqeyIezbSm5cqbrWlPuQqkHn5RlSJ6bGvH2Lj5m1DIlhBAeUGVKCCE8+Ki6+cZ67Vm8IKQXiwVSr0+IslzBWWd8ZmrtZ4zU2LdahtwZAtm/8/8NyOVMl5aV1laWSA0MUWnBYhWzb+SmKzmyi8V3s5/Xap5qG7VMCSGEB1SZEkIID6gyJYQQHjToMdNxrXtzpkNDpB4S3MuRxY/t3FnslpvOWafi62hrwqoZd1xvBCR331ghj8VZxY056QZlXeQtD5+qNb3+UShdWunrWs4J+VBNG2myeOaleZIFao3krnNuc23mqG5Ry5QQQnhAlSkhhPCgwXXz734luXOi3WlfzjKBnO5Ch/OS5yNmVrykRtHXzH7Iq2nlrFN8OYqb7kfq5ssi/YAazRWuctMVbfovi3/L+LNW80Q+nLee1KuepYfXKnyfSn7bw+IxuYm1na06Qy1TQgjhAVWmhBDCgwbXzW+98jsWy+vWV6lCl6L4bCSLhT0GSuZHbOKkK3meU+2mH8U34Uz/n6CJzHQp4lyZ8wn3jO+Uns9YLNDlPvMSUq/2zTguuVKiTNEhGFLnpg/KVChd0ALJw01KPqE72KhlSgghPKDKlBBCeECVKSGE8KDBjZk2+eFXqalf5ab7MOE8b48o61ZXyZO/moTIv/2l5GQEi7uk0eVQDdF6fXvOtPq00TLTlaac4Uw/VSmRLKMxU0IIIdKoMiWEEB40uG4++bTpWjeWvaC0mDN5dsnLOsgNUVbbpl+w2C3QjLNMRf9LmeuUJiZwpkOef5p3BFLLlBBCeECVKSGE8IC6+aTWSb+7S2jUUWaakrO7ONMjsi7UZpZILRO/lgzT+EUK6zEndYdapoQQwgOqTAkhhAfUzSd1SqXvYBbHd1/E4jVqOfWQG6KsZ3mSh5k89f6Ns6zj+aEsFr/JYvHxoie1n7EGgFqmhBDCA6pMCSGEB1SZEkIIDwRisVis7EpCtda1kRciR2mxiJftULnVLT7KjcqsbtWkzKhlSgghPKDKlBBCePBB3XxCCCFc1DIlhBAeUGVKCCE8oMqUEEJ4QJUpIYTwgCpTQgjhAVWmhBDCA6pMCSGEB1SZEkIID6gyJYQQHvw/EeBIn26BokkAAAAASUVORK5CYII="
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Создайте генераторы батчей."
   ],
   "metadata": {
    "id": "aypFdgXdZpGQ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Количество элементов в батче\n",
    "batch_size = 32\n",
    "\n",
    "train_batch_gen = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True\n",
    ")\n",
    "val_batch_gen = torch.utils.data.DataLoader(\n",
    "    val_dataset, batch_size=batch_size, shuffle=False\n",
    ")"
   ],
   "metadata": {
    "id": "ZxF48UxiZq2O",
    "ExecuteTime": {
     "end_time": "2024-03-15T22:09:03.960813Z",
     "start_time": "2024-03-15T22:09:03.935048Z"
    }
   },
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Эксперимент 1.** Создайте хотя бы 5 сверточных нейросетей с разным количеством линейных и сверточных слоев. Должен присутствовать хотя бы 1 сверточный слой и хотя бы 1 линейный слой. Для каждой посмотрите количество параметров с помощью `torchinfo.summary`."
   ],
   "metadata": {
    "id": "eKLKBG3OfBSR"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Модель с 1 свёрточным слоем и 1 линейным\n",
    "model_cnn_1_1 = nn.Sequential(\n",
    "    nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.ReLU(),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(in_features=5408, out_features=10),\n",
    ").to(device)\n",
    "\n",
    "summary(model_cnn_1_1, input_size=(1, 1, 28, 28))"
   ],
   "metadata": {
    "id": "XtDoy51q15s_",
    "ExecuteTime": {
     "end_time": "2024-03-16T06:26:31.443395Z",
     "start_time": "2024-03-16T06:26:31.401638Z"
    }
   },
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\nSequential                               [1, 10]                   --\n├─Conv2d: 1-1                            [1, 32, 26, 26]           320\n├─MaxPool2d: 1-2                         [1, 32, 13, 13]           --\n├─ReLU: 1-3                              [1, 32, 13, 13]           --\n├─Flatten: 1-4                           [1, 5408]                 --\n├─Linear: 1-5                            [1, 10]                   54,090\n==========================================================================================\nTotal params: 54,410\nTrainable params: 54,410\nNon-trainable params: 0\nTotal mult-adds (Units.MEGABYTES): 0.27\n==========================================================================================\nInput size (MB): 0.00\nForward/backward pass size (MB): 0.17\nParams size (MB): 0.22\nEstimated Total Size (MB): 0.39\n=========================================================================================="
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\nSequential                               [1, 10]                   --\n├─Conv2d: 1-1                            [1, 32, 26, 26]           320\n├─MaxPool2d: 1-2                         [1, 32, 13, 13]           --\n├─ReLU: 1-3                              [1, 32, 13, 13]           --\n├─Conv2d: 1-4                            [1, 64, 11, 11]           18,496\n├─MaxPool2d: 1-5                         [1, 64, 5, 5]             --\n├─ReLU: 1-6                              [1, 64, 5, 5]             --\n├─Flatten: 1-7                           [1, 1600]                 --\n├─Linear: 1-8                            [1, 10]                   16,010\n==========================================================================================\nTotal params: 34,826\nTrainable params: 34,826\nNon-trainable params: 0\nTotal mult-adds (Units.MEGABYTES): 2.47\n==========================================================================================\nInput size (MB): 0.00\nForward/backward pass size (MB): 0.24\nParams size (MB): 0.14\nEstimated Total Size (MB): 0.38\n=========================================================================================="
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Модель с 2 свёрточными слоями и 1 линейным\n",
    "model_cnn_2_1 = nn.Sequential(\n",
    "    nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.ReLU(),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(in_features=1600, out_features=10),\n",
    ").to(device)\n",
    "\n",
    "summary(model_cnn_2_1, input_size=(1, 1, 28, 28))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-16T06:28:26.939656Z",
     "start_time": "2024-03-16T06:28:26.910965Z"
    }
   },
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\nSequential                               [1, 10]                   --\n├─Conv2d: 1-1                            [1, 32, 26, 26]           320\n├─MaxPool2d: 1-2                         [1, 32, 13, 13]           --\n├─ReLU: 1-3                              [1, 32, 13, 13]           --\n├─Conv2d: 1-4                            [1, 64, 11, 11]           18,496\n├─MaxPool2d: 1-5                         [1, 64, 5, 5]             --\n├─ReLU: 1-6                              [1, 64, 5, 5]             --\n├─Flatten: 1-7                           [1, 1600]                 --\n├─Linear: 1-8                            [1, 256]                  409,856\n├─ReLU: 1-9                              [1, 256]                  --\n├─Linear: 1-10                           [1, 10]                   2,570\n==========================================================================================\nTotal params: 431,242\nTrainable params: 431,242\nNon-trainable params: 0\nTotal mult-adds (Units.MEGABYTES): 2.87\n==========================================================================================\nInput size (MB): 0.00\nForward/backward pass size (MB): 0.24\nParams size (MB): 1.72\nEstimated Total Size (MB): 1.97\n=========================================================================================="
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Модель с 2 свёрточными слоями и 2 линейными\n",
    "model_cnn_2_2 = nn.Sequential(\n",
    "    nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.ReLU(),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(in_features=1600, out_features=256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features=256, out_features=10),\n",
    ").to(device)\n",
    "\n",
    "summary(model_cnn_2_2, input_size=(1, 1, 28, 28))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-16T06:28:45.666035Z",
     "start_time": "2024-03-16T06:28:45.646700Z"
    }
   },
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\nSequential                               [1, 10]                   --\n├─Conv2d: 1-1                            [1, 32, 26, 26]           320\n├─MaxPool2d: 1-2                         [1, 32, 13, 13]           --\n├─ReLU: 1-3                              [1, 32, 13, 13]           --\n├─Conv2d: 1-4                            [1, 64, 11, 11]           18,496\n├─MaxPool2d: 1-5                         [1, 64, 5, 5]             --\n├─ReLU: 1-6                              [1, 64, 5, 5]             --\n├─Conv2d: 1-7                            [1, 256, 3, 3]            147,712\n├─MaxPool2d: 1-8                         [1, 256, 1, 1]            --\n├─ReLU: 1-9                              [1, 256, 1, 1]            --\n├─Flatten: 1-10                          [1, 256]                  --\n├─Linear: 1-11                           [1, 64]                   16,448\n├─ReLU: 1-12                             [1, 64]                   --\n├─Linear: 1-13                           [1, 10]                   650\n==========================================================================================\nTotal params: 183,626\nTrainable params: 183,626\nNon-trainable params: 0\nTotal mult-adds (Units.MEGABYTES): 3.80\n==========================================================================================\nInput size (MB): 0.00\nForward/backward pass size (MB): 0.25\nParams size (MB): 0.73\nEstimated Total Size (MB): 0.99\n=========================================================================================="
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Модель с 3 свёрточными слоями и 2 линейными\n",
    "model_cnn_3_2 = nn.Sequential(\n",
    "    nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(in_channels=64, out_channels=256, kernel_size=3),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.ReLU(),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(in_features=256, out_features=64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features=64, out_features=10),\n",
    ").to(device)\n",
    "\n",
    "summary(model_cnn_3_2, input_size=(1, 1, 28, 28))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-16T06:29:22.352717Z",
     "start_time": "2024-03-16T06:29:22.331266Z"
    }
   },
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\nSequential                               [1, 10]                   --\n├─Conv2d: 1-1                            [1, 32, 26, 26]           320\n├─MaxPool2d: 1-2                         [1, 32, 13, 13]           --\n├─ReLU: 1-3                              [1, 32, 13, 13]           --\n├─Conv2d: 1-4                            [1, 128, 11, 11]          36,992\n├─MaxPool2d: 1-5                         [1, 128, 5, 5]            --\n├─ReLU: 1-6                              [1, 128, 5, 5]            --\n├─Conv2d: 1-7                            [1, 256, 3, 3]            295,168\n├─MaxPool2d: 1-8                         [1, 256, 1, 1]            --\n├─ReLU: 1-9                              [1, 256, 1, 1]            --\n├─Flatten: 1-10                          [1, 256]                  --\n├─Linear: 1-11                           [1, 128]                  32,896\n├─ReLU: 1-12                             [1, 128]                  --\n├─Linear: 1-13                           [1, 32]                   4,128\n├─ReLU: 1-14                             [1, 32]                   --\n├─Linear: 1-15                           [1, 10]                   330\n==========================================================================================\nTotal params: 369,834\nTrainable params: 369,834\nNon-trainable params: 0\nTotal mult-adds (Units.MEGABYTES): 7.39\n==========================================================================================\nInput size (MB): 0.00\nForward/backward pass size (MB): 0.32\nParams size (MB): 1.48\nEstimated Total Size (MB): 1.80\n=========================================================================================="
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Модель с 3 свёрточными слоями и 3 линейными\n",
    "model_cnn_3_3 = nn.Sequential(\n",
    "    nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(in_channels=32, out_channels=128, kernel_size=3),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.ReLU(),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(in_features=256, out_features=128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features=128, out_features=32),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features=32, out_features=10),\n",
    ").to(device)\n",
    "\n",
    "summary(model_cnn_3_3, input_size=(1, 1, 28, 28))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-16T06:34:15.626558Z",
     "start_time": "2024-03-16T06:34:15.608098Z"
    }
   },
   "execution_count": 62
  },
  {
   "cell_type": "markdown",
   "source": [
    "Обучите сети, используя функцию потерь `nn.CrossEntropyLoss` и оптимизатор `torch.optim.Adam` с дефолтными параметрами."
   ],
   "metadata": {
    "id": "PQiEK0kQgUVs"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Создадим функции для обучения моделей, сохранения процесса обучения и визуализации."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def print_epoch(epoch, num_epochs, history, t):\n",
    "    \"\"\"\n",
    "    Функция для вывода информации про эпоху.\n",
    "    :param epoch: номер эпохи\n",
    "    :param num_epochs: общее количество эпох\n",
    "    :param history: (dict) accuracy и loss на обучении и валидации (\"история\" обучения)\n",
    "    :param t: время эпохи в секундах\n",
    "    \"\"\"\n",
    "    clear_output(wait=True)\n",
    "    print(\"Epoch {} of {} took {:.3f} s\".format(epoch + 1, num_epochs, t))\n",
    "    print(\"  training loss: \\t{:.6f}\".format(history[\"loss\"][\"train\"][-1]))\n",
    "    print(\"  validation loss: \\t{:.6f}\".format(history[\"loss\"][\"val\"][-1]))\n",
    "    print(\n",
    "        \"  training accuracy: \\t\\t\\t{:.2f} %\".format(\n",
    "            history[\"acc\"][\"train\"][-1] * 100\n",
    "        )\n",
    "    )\n",
    "    print(\n",
    "        \"  validation accuracy: \\t\\t\\t{:.2f} %\".format(\n",
    "            history[\"acc\"][\"val\"][-1] * 100\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "def update_history(history, loss, acc, num_batches, mode):\n",
    "    \"\"\"\n",
    "    Функция для сохранения лосса и точности в историю.\n",
    "    :param history: (dict) accuracy и loss на обучении и валидации (\"история\" обучения)\n",
    "    :param loss: сумма лосса за весь батч\n",
    "    :param acc: сумма точности за весь батч\n",
    "    :param num_batches: общее количество батчей\n",
    "    :param mode: train или val\n",
    "    \"\"\"\n",
    "    # Подсчитываем лоссы и сохраняем в \"историю\"\n",
    "    loss /= num_batches\n",
    "    acc /= num_batches\n",
    "    history[\"loss\"][mode].append(loss)\n",
    "    history[\"acc\"][mode].append(acc)\n",
    "\n",
    "\n",
    "def get_batch_loss(\n",
    "        X_batch, y_batch, model, criterion, current_loss, current_acc\n",
    "):\n",
    "    \"\"\"\n",
    "    Функция для подсчета лосса (без backward pass).\n",
    "    :param X_batch: батч картиок X\n",
    "    :param y_batch: батч меток y\n",
    "    :param model: модель для получения логитов\n",
    "    :param criterion: функция потерь\n",
    "    :param current_loss: текущий суммарный лосс за батч\n",
    "    :param current_acc: текущая суммарная точность за батч\n",
    "    :return: лосс на данном батче; current_loss; current_acc\n",
    "    \"\"\"\n",
    "\n",
    "    # Обучаемся на батче (одна \"итерация\" обучения нейросети)\n",
    "    X_batch = X_batch.to(device)\n",
    "    y_batch = y_batch.to(device)\n",
    "\n",
    "    # Логиты на выходе модели\n",
    "    logits = model(X_batch)\n",
    "\n",
    "    # Подсчитываем лосс\n",
    "    loss = criterion(logits, y_batch.long().to(device))\n",
    "\n",
    "    # Сохраняем лоссы и точность на трейне\n",
    "    current_loss += loss.detach().cpu().numpy()\n",
    "    y_pred = logits.max(1)[1].detach().cpu().numpy()\n",
    "    current_acc += np.mean(y_batch.cpu().numpy() == y_pred)\n",
    "    return loss, current_loss, current_acc\n",
    "\n",
    "\n",
    "def train(\n",
    "        model, criterion, optimizer, train_batch_gen, val_batch_gen, num_epochs=40\n",
    "):\n",
    "    \"\"\"\n",
    "    Функция для обучения модели и вывода лосса и метрики во время обучения.\n",
    "\n",
    "    :param model: обучаемая модель\n",
    "    :param criterion: функция потерь\n",
    "    :param optimizer: метод оптимизации\n",
    "    :param train_batch_gen: генератор батчей для обучения\n",
    "    :param val_batch_gen: генератор батчей для валидации\n",
    "    :param num_epochs: количество эпох\n",
    "    :return: (dict) accuracy и loss на обучении и валидации (\"история\" обучения)\n",
    "    \"\"\"\n",
    "\n",
    "    history = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, val_loss = 0, 0\n",
    "        train_acc, val_acc = 0, 0\n",
    "        start_time = time.time()\n",
    "\n",
    "        # ----------------------   ОБУЧЕНИЕ   ----------------------#\n",
    "        model.train(True)\n",
    "        # На каждой \"эпохе\" делаем полный проход по данным\n",
    "        for X_batch, y_batch in train_batch_gen:\n",
    "            # Считаем лосс, обновляем train_loss, train_acc\n",
    "            loss, train_loss, train_acc = get_batch_loss(\n",
    "                X_batch, y_batch, model, criterion, train_loss, train_acc\n",
    "            )\n",
    "\n",
    "            # Обратный проход\n",
    "            loss.backward()\n",
    "            # Шаг градиента\n",
    "            optimizer.step()\n",
    "            # Зануляем градиенты\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        # Подсчитываем лоссы и сохраняем в \"историю\"\n",
    "        update_history(\n",
    "            history, train_loss, train_acc, len(train_batch_gen), \"train\"\n",
    "        )\n",
    "\n",
    "        # ----------------------   ВАЛИДАЦИЯ   ----------------------#\n",
    "        model.train(False)\n",
    "        # Контекстный менеджер, отключающий подсчет градиентов\n",
    "        with torch.no_grad():\n",
    "            # Полный проход по валидационному датасету\n",
    "            for X_batch, y_batch in val_batch_gen:\n",
    "                # Считаем лосс, обновляем val_loss, val_acc\n",
    "                _, val_loss, val_acc = get_batch_loss(\n",
    "                    X_batch, y_batch, model, criterion, val_loss, val_acc\n",
    "                )\n",
    "\n",
    "        # Подсчитываем лоссы и сохраняем в \"историю\"\n",
    "        update_history(history, val_loss, val_acc, len(val_batch_gen), \"val\")\n",
    "\n",
    "        # Печатаем результаты после каждой эпохи\n",
    "        print_epoch(epoch, num_epochs, history, time.time() - start_time)\n",
    "\n",
    "    return history"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-16T06:21:50.036352Z",
     "start_time": "2024-03-16T06:21:49.962310Z"
    }
   },
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def plot_histories(histories, names):\n",
    "    \"\"\"\n",
    "    Функция для визуализации лосса и метрики по нескольким историям.\n",
    "    :param history: (list) список историй моделей\n",
    "    :param names: (list) список названий моделей\n",
    "    \"\"\"\n",
    "    sns.set_style(\"darkgrid\")\n",
    "    colors = [\"darkblue\", \"lightcoral\", \"limegreen\", \"sandybrown\"]\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "    epochs = np.min([len(h[\"loss\"][\"train\"]) for h in histories])\n",
    "    for i, (history, name) in enumerate(zip(histories, names)):\n",
    "        axs[0].set_title(\"Лосс\")\n",
    "        axs[0].plot(\n",
    "            history[\"loss\"][\"train\"][:epochs],\n",
    "            label=f\"{name}\",\n",
    "            lw=2,\n",
    "            c=colors[i],\n",
    "        )\n",
    "        axs[0].plot(\n",
    "            history[\"loss\"][\"val\"][:epochs], lw=1.5, c=colors[i], ls=\"--\"\n",
    "        )\n",
    "        axs[0].set_xlabel(\"Эпохи\")\n",
    "\n",
    "        axs[1].set_title(\"Точность\")\n",
    "        axs[1].plot(\n",
    "            history[\"acc\"][\"train\"][:epochs], label=f\"{name}\", lw=2, c=colors[i]\n",
    "        )\n",
    "        axs[1].plot(\n",
    "            history[\"acc\"][\"val\"][:epochs], lw=1.5, c=colors[i], ls=\"--\"\n",
    "        )\n",
    "        axs[1].set_xlabel(\"Эпохи\")\n",
    "        axs[1].legend()\n",
    "\n",
    "    dummy_lines = [\n",
    "        axs[0].plot([], [], c=\"black\", lw=2)[0],\n",
    "        axs[0].plot([], [], c=\"black\", lw=1.5, ls=\"--\")[0],\n",
    "    ]\n",
    "    for i in range(2):\n",
    "        legend = axs[i].legend(loc=3 - i)\n",
    "        axs[i].legend(dummy_lines, [\"train\", \"val\"], loc=4)\n",
    "        axs[i].add_artist(legend)\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-16T06:21:50.515152Z",
     "start_time": "2024-03-16T06:21:50.494876Z"
    }
   },
   "execution_count": 28
  },
  {
   "cell_type": "markdown",
   "source": [
    "Теперь мы готовы обучать модели, только нужно задать функцию потерь и оптимизаторы."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-29T02:06:46.314950Z",
     "iopub.status.busy": "2022-11-29T02:06:46.313963Z",
     "iopub.status.idle": "2022-11-29T02:15:25.832768Z",
     "shell.execute_reply": "2022-11-29T02:15:25.831808Z",
     "shell.execute_reply.started": "2022-11-29T02:06:46.314912Z"
    },
    "id": "EnEk2EiJVJog",
    "ExecuteTime": {
     "end_time": "2024-03-16T06:39:56.141413Z",
     "start_time": "2024-03-16T06:39:56.108086Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "models_experiment1 = [model_cnn_1_1, model_cnn_2_1, model_cnn_2_2, model_cnn_3_2, model_cnn_3_3]\n",
    "optimizer_experiment1 = [torch.optim.Adam(model.parameters()) for model in models_experiment1]"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[67], line 11\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;66;03m# Само обучение\u001B[39;00m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m model_num \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(models_experiment1)):\n\u001B[1;32m     10\u001B[0m     history_experiment1\u001B[38;5;241m.\u001B[39mappend(\n\u001B[0;32m---> 11\u001B[0m         \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     12\u001B[0m \u001B[43m            \u001B[49m\u001B[43mmodels_experiment1\u001B[49m\u001B[43m[\u001B[49m\u001B[43mmodel_num\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     13\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     14\u001B[0m \u001B[43m            \u001B[49m\u001B[43moptimizer_experiment1\u001B[49m\u001B[43m[\u001B[49m\u001B[43mmodel_num\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     15\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtrain_batch_gen\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     16\u001B[0m \u001B[43m            \u001B[49m\u001B[43mval_batch_gen\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     17\u001B[0m \u001B[43m            \u001B[49m\u001B[43mnum_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\n\u001B[1;32m     18\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     19\u001B[0m     )\n\u001B[1;32m     20\u001B[0m     torch\u001B[38;5;241m.\u001B[39msave(models_experiment1[model_num]\u001B[38;5;241m.\u001B[39mstate_dict(), \n\u001B[1;32m     21\u001B[0m                \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mexper1_models_name_save[model_num]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.pth\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[0;32mIn[27], line 97\u001B[0m, in \u001B[0;36mtrain\u001B[0;34m(model, criterion, optimizer, train_batch_gen, val_batch_gen, num_epochs)\u001B[0m\n\u001B[1;32m     95\u001B[0m model\u001B[38;5;241m.\u001B[39mtrain(\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m     96\u001B[0m \u001B[38;5;66;03m# На каждой \"эпохе\" делаем полный проход по данным\u001B[39;00m\n\u001B[0;32m---> 97\u001B[0m \u001B[43m\u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mX_batch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_batch\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtrain_batch_gen\u001B[49m\u001B[43m:\u001B[49m\n\u001B[1;32m     98\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# Считаем лосс, обновляем train_loss, train_acc\u001B[39;49;00m\n\u001B[1;32m     99\u001B[0m \u001B[43m    \u001B[49m\u001B[43mloss\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loss\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_acc\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mget_batch_loss\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    100\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX_batch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_batch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loss\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_acc\u001B[49m\n\u001B[1;32m    101\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    103\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# Обратный проход\u001B[39;49;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/mipt-stats/lib/python3.12/site-packages/torch/utils/data/dataloader.py:631\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    628\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    629\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[1;32m    630\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[0;32m--> 631\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    632\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    633\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    634\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    635\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[0;32m~/anaconda3/envs/mipt-stats/lib/python3.12/site-packages/torch/utils/data/dataloader.py:675\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    673\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    674\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m--> 675\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m    676\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[1;32m    677\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[0;32m~/anaconda3/envs/mipt-stats/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:51\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[0;34m(self, possibly_batched_index)\u001B[0m\n\u001B[1;32m     49\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[1;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 51\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[1;32m     52\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     53\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[0;32m~/anaconda3/envs/mipt-stats/lib/python3.12/site-packages/torchvision/datasets/mnist.py:138\u001B[0m, in \u001B[0;36mMNIST.__getitem__\u001B[0;34m(self, index)\u001B[0m\n\u001B[1;32m    130\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__getitem__\u001B[39m(\u001B[38;5;28mself\u001B[39m, index: \u001B[38;5;28mint\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[Any, Any]:\n\u001B[1;32m    131\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    132\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[1;32m    133\u001B[0m \u001B[38;5;124;03m        index (int): Index\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    136\u001B[0m \u001B[38;5;124;03m        tuple: (image, target) where target is index of the target class.\u001B[39;00m\n\u001B[1;32m    137\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 138\u001B[0m     img, target \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdata[index], \u001B[38;5;28;43mint\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtargets\u001B[49m\u001B[43m[\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    140\u001B[0m     \u001B[38;5;66;03m# doing this so that it is consistent with all other datasets\u001B[39;00m\n\u001B[1;32m    141\u001B[0m     \u001B[38;5;66;03m# to return a PIL Image\u001B[39;00m\n\u001B[1;32m    142\u001B[0m     img \u001B[38;5;241m=\u001B[39m Image\u001B[38;5;241m.\u001B[39mfromarray(img\u001B[38;5;241m.\u001B[39mnumpy(), mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mL\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Будем сохранять историю обучения моделей\n",
    "history_experiment1 = []\n",
    "\n",
    "# Название файлов для сохранения параметров\n",
    "exper1_models_name = [\"cnn_1_1\", \"cnn_2_1\", \"cnn_2_2\", \n",
    "                           \"cnn_3_2\", \"cnn_3_3\"]\n",
    "\n",
    "# Само обучение\n",
    "for model_num in range(len(models_experiment1)):\n",
    "    history_experiment1.append(\n",
    "        train(\n",
    "            models_experiment1[model_num],\n",
    "            criterion,\n",
    "            optimizer_experiment1[model_num],\n",
    "            train_batch_gen,\n",
    "            val_batch_gen,\n",
    "            num_epochs=1\n",
    "        )\n",
    "    )\n",
    "    torch.save(models_experiment1[model_num].state_dict(), \n",
    "               f\"{exper1_models_name_save[model_num]}.pth\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-16T06:49:27.190464Z",
     "start_time": "2024-03-16T06:49:25.484445Z"
    }
   },
   "execution_count": 67
  },
  {
   "cell_type": "markdown",
   "source": [
    "Постройте график лосса и график accuracy, где сравниваются все модели (на train и на val). Нужная функция есть в семинаре."
   ],
   "metadata": {
    "id": "HKeKUcptgylG"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "plot_histories(models_experiment1, exper1_models_name)"
   ],
   "metadata": {
    "id": "C-tIcHs_bZ28"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Сделайте вывод. Как количество разных слоев влияет на качество и время обучения?\n",
    "\n",
    "**Вывод по эксперименту 1:** <...>"
   ],
   "metadata": {
    "id": "dm2vwgrVlkj-"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Эксперимент 2.** Теперь выберите лучший вариант, зафиксируйте это количество сверточных и линейных слоев и обучите хотя бы 4 сверточных нейросети, варьируя размеры ядер сверток. Например, в разном порядке поставьте ядра 3x3, 5x5."
   ],
   "metadata": {
    "id": "htYb8OWXehWB"
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "vGaa6OZKfxuz"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Постройте график лосса и график accuracy, где сравниваются все модели этого эксперимента (на train и на val)."
   ],
   "metadata": {
    "id": "cgvL8CP6fype"
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "dW4ZP422fypf"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Сделайте вывод. Как размеры ядер влияют на качество и время обучения?\n",
    "\n",
    "**Вывод по эксперименту 2:** <...>"
   ],
   "metadata": {
    "id": "MUy9v-IAltAP"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Анализ лучшей модели.** Выберите лучшую конфигурацию из всех по accuracy на валидации. Она должна быть не меньше 98%."
   ],
   "metadata": {
    "id": "bqLZr0CCdV-p"
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "ztRtP5VtgQ3h"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Проведите еще один проход валидации выбранной моделью по всему датасету. В нем посчитайте точность по каждому классу и соберите информацию о неправильных предсказаниях. Равномерна ли точность по отношению к классам? Покажите 10-20 примеров, на которых нейросеть выдала неправильную метку. Что можно о них сказать?"
   ],
   "metadata": {
    "id": "TMPEvu2bg3Zc"
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "A94g5BGz6uU4"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KVfdfsXZnhcs"
   },
   "source": [
    "**Ответ:** <...>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a_EvDaB7W2Q2"
   },
   "source": [
    "**Вывод по всей задаче:** <...>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EWHsMVWwW2Q2"
   },
   "source": [
    "---\n",
    "### Задача 2. Перенос стиля"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Здесь вы потренируетесь в работе с картинками и составлением промптов. Используя код с <a href=\"https://miptstats.github.io/courses/ad_fivt/CV_complex_examples.html\" target=\"_blank\">семинара</a>, проведите перенос стиля на хотя бы 3 своих примерах.\n",
    "\n",
    "> Заметьте, что в примерах с семинара в качестве картинок стиля и контента использовались картинки среднего разрешения. Если возникают проблемы: оптимизация останавливается на 0-й эпохе и не создает картинку; loss в какой-то момент стал nan; нехватка RAM; &mdash; то либо уменьшите разрешение ваших картинок, либо попробуйте картинку полегче."
   ],
   "metadata": {
    "id": "33gKkfQz2mIx"
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "Syn9JDq04ISQ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Теперь для каждой пары контекст-стиль попытайтесь сгенерировать картинку с таким контекстом и стилем с помощью диффузионной модели, рассмотренной на семинаре, задав нужный промпт."
   ],
   "metadata": {
    "id": "I2yeDQMz4IiY"
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "oQ_6F1NP47ot"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zPoMmyGgW2Q3"
   },
   "source": [
    "**Вывод:**\n",
    "<...>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
